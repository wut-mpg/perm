---
layout: task
title: Ćwiczenie wprowadzające
category: lab
lab: 5
task: 1
brief: Kalibracja parametrów zestawu kamer oraz reprojekcja 3D
---


## Kalibracja

W celu wyznaczenia położenia wybranych punktów w przestrzeni na podstawie pary obrazów,
konieczna jest znajomość parametrów zestawu stereo (schematycznie przedstawionego poniżej).
Oprócz parametrów wewnętrznych każdej z kamer (takich jak _f_ i _c_, które wyznaczane były
także w [poprzednim zadaniu]({{site.baseurl}}{% post_url 2020-04-16-calib %}))
konieczna jest znajomość wzajemnego położenia i orientacji kamer. 

![]({{site.baseurl}}/public/l5/stereo-geom.jpg)

Zwykle dąży się do stanu, w którym kamery mają równoległe osie optyczne, a ich odległość
jest znana i zadana z góry. W rzeczywistości jednak nie da się tego zrobić bezbłędnie,
w związku z czym parametry te podlegają procesowi kalibracji (podobnie jak macierz kamery).
W tym celu wykorzystać można Stereo Camera Calibrator App (można też zaimplementować podobny 
proces ręcznie korzystając z funkcji [rectifyStereoImages](https://uk.mathworks.com/help/vision/ref/rectifystereoimages.html)).

Proces kalibracji przebiega podobnie jak przy pojedynczej kamerze. Po podaniu zestawów obrazów 
dla lewej i prawej kamery wyznaczone zostaną wszystkie istotne parametry.


![]({{site.baseurl}}/public/l5/calib_1.jpg)

## Prostowanie obrazu

Po wyznaczeniu wszystkich parametrów zestawu stereo możliwe jest przeprowadzenie procesu
prostowania obrazu (_rectification_). Po wybraniu opcji __show rectified__ obrazy zostaną
wyrównane, dodatkowo zostanie na nich wyświetlona siatka pozioma ułątwiająca odnalezienie 
odpowiadających sobie punktów. 

![]({{site.baseurl}}/public/l5/calib_2.jpg)

Wyznaczone parametry kalibracyjne proszę wyeksportować do zmiennej __stereoParams__.
W wyznaczonych parametrach znajdują się parametry obu kamer (powinny być zbliżone do siebie)
a także ich wzajemne położenie. Zwykle lewa kamera traktowana jest jako punkt odniesienia,
a więc jej położenie i orientacja są zerowe. Prawa kamera powinna znajdować się kilka cm obok
lewej, a jej orientacja powinna być zbliżona do lewej.

## Określenie zakresu _disparity_

W celu wyznaczenia prawidłowego obrazu głębi przydaje się znajomość zakresu,
w jakim zmienia się _disparity_ punktów. Jest ono największe dla obiektów znajdujących
się blisko kamery i zmniejsza się wraz z oddalaniem. Po wyprostowaniu obrazów można 
zmierzyć te parametry dla przykłądowych obiektów.

{% highlight matlab %}
% read pair of images
I1 = imread('left/left-0000.png');
I2 = imread('right/right-0000.png');

% rectify images using calculated stereo parameters
[J1, J2] = rectifyStereoImages(I1, I2, stereoParams);
{% endhighlight %}

Na wyświetlonym podwójnym obrazie można zmierzyć odległość pomiędzy odpowiadającymi sobie punktami 
blisko kamery (na szachownicy) oraz daleko (na ścianie). 

{% highlight matlab %}
imtool(cat(3, J1, J2, J2));
{% endhighlight %}

W przykładzie powyżej zakres ten wynosi między 80 a 161 piksele. Na niektórych zdjęciach 
obiekt znajduje się bliżej, więc maksymalna wartość tego parametru może ulec zmianie 
(dla danego zestawu testowego dobrym zakresem jest między 64 a 400).

![]({{site.baseurl}}/public/l5/imtool_1.jpg)

## Wyznaczenie _disparity map_

Wykorzystując funkcję [disparity](https://www.mathworks.com/help/vision/ref/disparity.html) 
można wyznaczyć mapę niezgodności (_disparity map_) dla zadanej pary wyprostowanych obrazów.
Funkcja ta przyjmuje kilka parametrów, z których najważniejsze to zakres mierzonych odległości
(wyznaczony w poprzednim kroku), wielkość analizowanego bloku oraz progi odrzucania niepewnych 
dopasowań. Przy zastosowaniu parametrów domyślnych wynik nie jest zachwycający:

{% highlight matlab %}
% disparity range
dispRange = [0, 64];
disparityMap = disparity(J1, J2, ...
    'DisparityRange', dispRange, ...
    'BlockSize', 15, ...
    'ContrastThreshold', 0.5, ...
    'UniquenessThreshold', 15 );
	
% show disparity map
figure 
imshow(disparityMap, dispRange);
colormap(gca,jet) 
colorbar
{% endhighlight %}

![]({{site.baseurl}}/public/l5/disparity_1.jpg)

## Reprojekcja punktów do 3D

Korzystając z _disparity map_ możliwe jest wyznaczenie współrzędnych obserwowanych punktów
w przestrzeni 3D (X, Y, Z). Dla mapy powyżej wynik jest niepoprawny - obraz nie odpowiada 
scenie rzeczywistej.

{% highlight matlab %}
points3D = reconstructScene(disparityMap, stereoParams);

% expand gray image to three channels (simulate RGB)
J1_col = cat(3, J1, J1, J1);

% Convert to meters and create a pointCloud object
points3D = points3D ./ 1000;
ptCloud = pointCloud(points3D, 'Color', J1_col);

% Create a streaming point cloud viewer
player3D = pcplayer([-3, 3], [-3, 3], [0, 8], 'VerticalAxis', 'y', ...
    'VerticalAxisDir', 'down');

% Visualize the point cloud
view(player3D, ptCloud);
{% endhighlight %}

![]({{site.baseurl}}/public/l5/3d_1.jpg)

## Oczekiwany wynik

Po poprawieniu parametrów w funkcji __disparity__ (największy wpływ na wynik ma __disparity range__)
możliwe jest uzyskanie znacznie lepszych wyników:

![]({{site.baseurl}}/public/l5/disparity_2.jpg)
![]({{site.baseurl}}/public/l5/3d_2.jpg)

## Dataset

   * [stereo_1](https://drive.google.com/uc?export=download&id=1J_fPjy3ZiWnNdiqVBxsBohoY2sX2ApfX)
